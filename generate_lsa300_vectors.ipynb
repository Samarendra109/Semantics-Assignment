{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0c22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2f770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "punctuation = set(list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea194c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = brown.words()\n",
    "words = [word.lower() for word in words]\n",
    "words = [word for word in words if word.isalpha()]\n",
    "words = [word for word in words if word not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956bed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_words = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ee1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = sorted(f_words.most_common(5000), key= lambda tup: tup[1])\n",
    "most_common_words = [tup[0] for tup in most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934c01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_words = ['cord', 'smile', 'hill', 'woodland', 'rooster', 'voyage', 'car', 'journey', 'noon',\n",
    "         'string', 'cemetery', 'mound', 'fruit', 'furnace', 'glass', 'jewel', 'autograph', 'shore',\n",
    "         'magician', 'oracle', 'automobile', 'wizard', 'crane', 'implement', 'mound', 'stove',\n",
    "         'brother', 'lad', 'grin', 'implement', 'sage', 'wizard', 'asylum', 'fruit', 'oracle',\n",
    "         'bird', 'sage', 'asylum', 'monk', 'graveyard', 'crane', 'madhouse', 'bird', 'cock', 'glass',\n",
    "         'magician', 'rooster', 'brother', 'monk', 'food', 'fruit', 'cushion', 'jewel', 'asylum',\n",
    "         'madhouse', 'monk', 'slave', 'cemetery', 'magician', 'wizard', 'furnace', 'stove', 'asylum',\n",
    "         'coast', 'forest', 'hill', 'mound', 'grin', 'lad', 'cord', 'string', 'shore', 'woodland',\n",
    "         'glass', 'tumbler', 'monk', 'oracle', 'grin', 'smile', 'boy', 'sage', 'serf', 'slave',\n",
    "         'automobile', 'cushion', 'journey', 'voyage', 'mound', 'shore', 'autograph', 'signature',\n",
    "         'lad', 'wizard', 'coast', 'shore', 'forest', 'graveyard', 'forest', 'woodland', 'food',\n",
    "         'rooster', 'implement', 'tool', 'cemetery', 'woodland', 'cock', 'rooster', 'shore', 'voyage',\n",
    "         'boy', 'Ind', 'bird', 'woodland', 'cushion', 'coast', 'hill', 'cemetery', 'furnace',\n",
    "         'implement', 'automobile', 'crane', 'rooster', 'midday', 'nооn', 'gem', 'jewel', 'boy',\n",
    "         'pillow', 'graveyard', 'car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992d6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = set(table_words + most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f86f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = ngrams(words, 2)\n",
    "bigram_counter = Counter(bi_grams)\n",
    "final_words_list = list(final_words)\n",
    "count_df = pd.DataFrame(columns=final_words_list, index=final_words_list)\n",
    "pmi_df  = pd.DataFrame(columns=final_words_list, index=final_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4a5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_set = set((w1,w2) for w1,w2 in ngrams(words, 2))\n",
    "bigrams_list = [(w1,w2) for w1,w2 in ngrams(words, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa515062",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1,word2 in bigram_set:\n",
    "    if word1 in final_words and word2 in final_words:\n",
    "        bigram_count = bigram_counter[(word1, word2)]\n",
    "        count_df[word1].loc[word2] = bigram_count\n",
    "        bigram_prob = bigram_count/len(bigrams_list)\n",
    "        word1_prob = f_words[word1]/len(words)\n",
    "        word2_prob = f_words[word2]/len(words)\n",
    "        pmi_df[word1].loc[word2] = np.log2(bigram_prob/(word1_prob*word2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6fc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi_df = pmi_df.copy()\n",
    "ppmi_df[ppmi_df < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b7fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {w:i for i,w in enumerate(final_words_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea346859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "result = PCA(300).fit_transform(ppmi_df.fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73b0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_mat_10  = result[:,:10]\n",
    "lsa_mat_100 = result[:,:100]\n",
    "lsa_mat_300 = result[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df8d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"lsa_word_vec_with_word_index300_final1.pkl\", 'wb') as f:\n",
    "    pickle.dump((lsa_mat_300, word_to_index), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95aaba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767ab5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n11_grams = ngrams(words, 5)\n",
    "n11gram_counter = Counter(n11_grams)\n",
    "pmi_5_df  = pd.DataFrame(columns=final_words_list, index=final_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3faf712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n11gram_set = set(tuple(gram) for gram in ngrams(words, 5))\n",
    "n11grams_list = [tuple(gram) for gram in ngrams(words, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4f4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p5_counter = {}\n",
    "for word_gram in n11grams_list:\n",
    "    word1 = word_gram[2]\n",
    "    for i, word2 in enumerate(word_gram):\n",
    "        if i != 2:\n",
    "            p5_counter[(word1, word2)] = p5_counter.get((word1, word2), 0) + 1/np.abs(i-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d22239",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1,word2 in p5_counter:\n",
    "    if word1 in final_words and word2 in final_words:\n",
    "        cooccur_count = p5_counter[(word1, word2)]\n",
    "        cooccur_prob = cooccur_count/len(n11grams_list)\n",
    "        word1_prob = f_words[word1]/len(words)\n",
    "        word2_prob = f_words[word2]/len(words)\n",
    "        pmi_5_df[word1].loc[word2] = np.log2(cooccur_prob/(word1_prob*word2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c8f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = PCA(300).fit_transform(pmi_5_df.fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41c9977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"lsa_word_vec_with_word_index300_final2_con5.pkl\", 'wb') as f:\n",
    "    pickle.dump((result, word_to_index), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedf687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
